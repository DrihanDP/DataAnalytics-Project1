{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57432e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#NASA Turbofan Engine Degradation reliability and failure analysis#\n",
    "###################################################################\n",
    "#\n",
    "# File structure and SQL update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e52ea251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9dd559a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x255abfb7850>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create connection\n",
    "engine = create_engine(\"postgresql://postgres:Project1-NASA@localhost:5432/Project1-NASA\")\n",
    "\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "549d2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column names per readme.txt\n",
    "column_names = (\n",
    "    [\"engine_id\", \"cycle\"] + [f\"op_setting_{num}\" for num in range(1,4)] + [f\"sensor_{num}\" for num in range(1,22)]\n",
    ")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# create a dataframe and populate with first file of data (r\"\\s+\" is a regular expression for any amount of white space)\n",
    "# The code below has been commented due to it just being test \n",
    "# df = pd.read_csv(\"train_FD001.txt\", sep=r\"\\s+\", header=None, names=column_names)\n",
    "\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09f77b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional columns to determine file once combined\n",
    "df[\"dataset_id\"] = 'FD001'\n",
    "df[\"dataset_split\"] = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75b33a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send to sql\n",
    "df.to_sql(\"engine_readings\", engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c09ed252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test_FD001.txt\n",
      "Loaded test_FD002.txt\n",
      "Loaded test_FD003.txt\n",
      "Loaded test_FD004.txt\n",
      "Loaded train_FD001.txt\n",
      "Loaded train_FD002.txt\n",
      "Loaded train_FD003.txt\n",
      "Loaded train_FD004.txt\n"
     ]
    }
   ],
   "source": [
    "# Repeat for all files \n",
    "files = [\n",
    "    ('test_FD001.txt', \"FD001\", 'test'),\n",
    "    ('test_FD002.txt', \"FD002\", 'test'),\n",
    "    ('test_FD003.txt', \"FD003\", 'test'),\n",
    "    ('test_FD004.txt', \"FD004\", 'test'),\n",
    "    ('train_FD001.txt', \"FD001\", 'train'),\n",
    "    ('train_FD002.txt', \"FD002\", 'train'),\n",
    "    ('train_FD003.txt', \"FD003\", 'train'),\n",
    "    ('train_FD004.txt', \"FD004\", 'train'),\n",
    "]\n",
    "\n",
    "for file_name, id, split in files:\n",
    "    df = pd.read_csv(file_name, sep=r\"\\s+\", header=None, names=column_names)\n",
    "    \n",
    "    df[\"dataset_id\"] = id\n",
    "    df[\"dataset_split\"] = split\n",
    "\n",
    "    df.to_sql(\"engine_readings\", engine, if_exists='append', index=False)\n",
    "\n",
    "    print(f\"Loaded {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f094931d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 0.0023, 0.0003, 100.0, 518.67, 643.02, 1585.29, 1398.21, 14.62, 21.61, 553.9, 2388.04, 9050.17, 1.3, 47.2, 521.72, 2388.03, 8125.55, 8.4052, 0.03, 392.0, 2388.0, 100.0, 38.86, 23.3735, 'FD001', 'test')\n",
      "(1, 2, -0.0027, -0.0003, 100.0, 518.67, 641.71, 1588.45, 1395.42, 14.62, 21.61, 554.85, 2388.01, 9054.42, 1.3, 47.5, 522.16, 2388.06, 8139.62, 8.3803, 0.03, 393.0, 2388.0, 100.0, 39.02, 23.3916, 'FD001', 'test')\n",
      "(1, 3, 0.0003, 0.0001, 100.0, 518.67, 642.46, 1586.94, 1401.34, 14.62, 21.61, 554.11, 2388.05, 9056.96, 1.3, 47.5, 521.97, 2388.03, 8130.1, 8.4441, 0.03, 393.0, 2388.0, 100.0, 39.08, 23.4166, 'FD001', 'test')\n",
      "(1, 4, 0.0042, 0.0, 100.0, 518.67, 642.44, 1584.12, 1406.42, 14.62, 21.61, 554.07, 2388.03, 9045.29, 1.3, 47.28, 521.38, 2388.05, 8132.9, 8.3917, 0.03, 391.0, 2388.0, 100.0, 39.0, 23.3737, 'FD001', 'test')\n",
      "(1, 5, 0.0014, 0.0, 100.0, 518.67, 642.51, 1587.19, 1401.92, 14.62, 21.61, 554.16, 2388.01, 9044.55, 1.3, 47.31, 522.15, 2388.03, 8129.54, 8.4031, 0.03, 390.0, 2388.0, 100.0, 38.99, 23.413, 'FD001', 'test')\n",
      "(1, 6, 0.0012, 0.0003, 100.0, 518.67, 642.11, 1579.12, 1395.13, 14.62, 21.61, 554.22, 2388.0, 9050.96, 1.3, 47.26, 521.92, 2388.08, 8127.46, 8.4238, 0.03, 392.0, 2388.0, 100.0, 38.91, 23.3467, 'FD001', 'test')\n",
      "(1, 7, 0.0, 0.0002, 100.0, 518.67, 642.11, 1583.34, 1404.84, 14.62, 21.61, 553.89, 2388.05, 9051.39, 1.3, 47.31, 522.01, 2388.06, 8134.97, 8.3914, 0.03, 391.0, 2388.0, 100.0, 38.85, 23.3952, 'FD001', 'test')\n",
      "(1, 8, 0.0006, 0.0, 100.0, 518.67, 642.54, 1580.89, 1400.89, 14.62, 21.61, 553.59, 2388.05, 9052.86, 1.3, 47.21, 522.09, 2388.06, 8125.93, 8.4213, 0.03, 393.0, 2388.0, 100.0, 39.05, 23.3224, 'FD001', 'test')\n",
      "(1, 9, -0.0036, 0.0, 100.0, 518.67, 641.88, 1593.29, 1412.28, 14.62, 21.61, 554.49, 2388.06, 9048.55, 1.3, 47.37, 522.03, 2388.05, 8134.15, 8.4353, 0.03, 391.0, 2388.0, 100.0, 39.1, 23.4521, 'FD001', 'test')\n",
      "(1, 10, -0.0025, -0.0001, 100.0, 518.67, 642.07, 1585.25, 1398.64, 14.62, 21.61, 554.28, 2388.04, 9051.95, 1.3, 47.14, 522.0, 2388.06, 8134.08, 8.4093, 0.03, 391.0, 2388.0, 100.0, 38.87, 23.382, 'FD001', 'test')\n"
     ]
    }
   ],
   "source": [
    "# connecting to postgresql and retrieving the data that has been stored to it\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text('SELECT * FROM engine_readings LIMIT 10'))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ccd7e500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('FD001', 'test', 13096)\n",
      "('FD001', 'train', 20631)\n",
      "('FD002', 'test', 33991)\n",
      "('FD002', 'train', 53759)\n",
      "('FD003', 'test', 16596)\n",
      "('FD003', 'train', 24720)\n",
      "('FD004', 'test', 41214)\n",
      "('FD004', 'train', 61249)\n"
     ]
    }
   ],
   "source": [
    "# group and count to check if all the data has been updated\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text('''SELECT dataset_id, dataset_split, COUNT(*) AS row_count FROM engine_readings \n",
    "                                     GROUP BY dataset_id, dataset_split \n",
    "                                     ORDER BY dataset_id, dataset_split'''))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b47d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
